{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mMNV1rDxoJiq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Principais"
      ],
      "metadata": {
        "id": "mMNV1rDxoJiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Pandas:\n",
        "\n",
        "* Descrição: Ferramenta poderosa para manipulação e análise de dados.\n",
        "* Funcionalidades: Manipulação de dados tabulares (DataFrames), leitura e escrita em vários formatos de arquivo (CSV, Excel, SQL, etc.), tratamento de dados ausentes, agregações e agrupamentos de dados.\n",
        "\n",
        "2. NumPy:\n",
        "* Descrição: Biblioteca fundamental para computação científica em Python.\n",
        "* Funcionalidades: Suporte a arrays multidimensionais, funções matemáticas avançadas, álgebra linear, transformadas de Fourier, e geração de números aleatórios.\n",
        "\n",
        "3. Matplotlib:\n",
        "* Descrição: Biblioteca de plotagem 2D muito utilizada para visualização de dados.\n",
        "* Funcionalidades: Criação de gráficos variados (linhas, barras, histogramas, scatter plots), personalização avançada de gráficos, suporte a visualizações interativas com o módulo mpl_toolkits.\n",
        "\n",
        "4. Seaborn:\n",
        "* Descrição: Biblioteca de visualização de dados baseada no Matplotlib, com uma interface mais amigável.\n",
        "* Funcionalidades: Gráficos estatísticos mais atraentes e informativos, integração com pandas DataFrames, gráficos de regressão, heatmaps, entre outros.\n",
        "\n",
        "5. Scikit-learn:\n",
        "* Descrição: Biblioteca para machine learning em Python.\n",
        "* Funcionalidades: Implementação de uma variedade de algoritmos de machine learning (classificação, regressão, clustering), pré-processamento de dados, seleção de modelos, validação cruzada.\n",
        "\n",
        "6. SciPy:\n",
        "* Descrição: Biblioteca usada para computação científica e técnica.\n",
        "* Funcionalidades: Otimização, integração, interpolação, álgebra linear, estatísticas, e outras tarefas científicas e de engenharia.\n",
        "\n",
        "7. TensorFlow e PyTorch:\n",
        "* Descrição: Bibliotecas de deep learning amplamente utilizadas.\n",
        "* Funcionalidades: Criação e treinamento de redes neurais, suporte para computação em GPUs, construção de modelos complexos de aprendizado profundo.\n",
        "\n",
        "8. Statsmodels:\n",
        "* Descrição: Biblioteca para estimar e testar modelos estatísticos.\n",
        "* Funcionalidades: Modelos de regressão linear e não-linear, séries temporais, testes estatísticos, modelos de efeitos mistos, entre outros.\n",
        "\n",
        "9. Plotly:\n",
        "* Descrição: Biblioteca para criação de gráficos interativos e publicação de visualizações.\n",
        "* Funcionalidades: Gráficos interativos (2D e 3D), mapas, dashboards interativos, integração com notebooks Jupyter.\n",
        "\n",
        "10. BeautifulSoup e Scrapy:\n",
        "* Descrição: Bibliotecas para web scraping.\n",
        "* Funcionalidades: Extração de dados de HTML e XML, navegação em páginas da web, scraping de dados para análise posterior."
      ],
      "metadata": {
        "id": "Z5EfL0f2nRTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pulo do gato"
      ],
      "metadata": {
        "id": "nJEWQPeWoNaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lazy predict"
      ],
      "metadata": {
        "id": "YncWK0HloeHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LazyPredict é uma biblioteca em Python que permite a você rapidamente treinar e comparar vários modelos de machine learning sem a necessidade de escrever muito código. Ela fornece uma visão geral rápida de como diferentes algoritmos se comportam com seu conjunto de dados, ajudando a identificar quais modelos podem ser mais promissores.\n",
        "Principais Funcionalidades:\n",
        "\n",
        "* Treinamento Rápido: Treina e avalia múltiplos modelos de machine learning com apenas algumas linhas de código.\n",
        "* Comparação de Modelos: Retorna métricas de desempenho de diferentes modelos, facilitando a comparação e seleção do melhor modelo.\n",
        "* Economia de Tempo: Ideal para uma análise inicial rápida, permitindo que você foque em ajustar e otimizar os modelos mais promissores.\n",
        "\n",
        "1. Principais Métricas Retornadas:\n",
        "\n",
        "* Accuracy: Precisão do modelo.\n",
        "* Balanced Accuracy: Precisão balanceada do modelo.\n",
        "* ROC AUC: Área sob a curva ROC.\n",
        "* F1 Score: Média harmônica da precisão e sensibilidade.\n",
        "* Time Taken: Tempo total gasto para treinar e avaliar o modelo.\n",
        "\n",
        "2. Vantagens e Limitações:\n",
        "  \n",
        "  2.1 Vantagens:\n",
        "\n",
        "* Rapidez: Permite uma visão geral rápida de vários modelos.\n",
        "* Facilidade de Uso: Muito fácil de configurar e usar.\n",
        "* Comparação Inicial: Útil para uma análise inicial e para selecionar modelos promissores para afinação e otimização posterior.\n",
        "\n",
        "  2.2 Limitações:\n",
        "\n",
        "* Falta de Personalização: Pode não ser adequada para casos em que a personalização e a otimização detalhada são necessárias.\n",
        "* Desempenho Limitado: Útil apenas para uma visão geral; a otimização e afinação posteriores ainda são necessárias para uso em produção."
      ],
      "metadata": {
        "id": "YponG8AbojZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Codigo"
      ],
      "metadata": {
        "id": "nOfVlchRpYMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lazypredict"
      ],
      "metadata": {
        "id": "AGPSqLiQEdAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Carregar dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Dividir dataset em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inicializar LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Treinar e avaliar modelos\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(models)"
      ],
      "metadata": {
        "id": "1LGdzRBpoxMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## H2O.ai"
      ],
      "metadata": {
        "id": "x-_GCZ-fpfJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descrição: H2O.ai é uma plataforma de machine learning que oferece AutoML para a criação, otimização e implementação de modelos de machine learning.\n",
        "\n",
        "Principais Funcionalidades:\n",
        "\n",
        "* AutoML: Automatiza o processo de seleção de modelos e otimização de hiperparâmetros.\n",
        "* Suporte a Múltiplos Modelos: Suporte para uma ampla gama de modelos, incluindo gradient boosting, deep learning e ensembles.\n",
        "* Interface Web: Interface gráfica para facilitar a análise e visualização de resultados.\n",
        "\n",
        "1. metricas:\n",
        "Tabela de Modelos:\n",
        "Após a conclusão do AutoML, ele gera uma tabela com os modelos treinados, junto com suas métricas de desempenho.\n",
        "As métricas incluem\n",
        "* RMSE (Root Mean Squared Error),\n",
        "* MSE (Mean Squared Error),\n",
        "* MAE (Mean Absolute Error),\n",
        "* RMSLE (Root Mean Squared Logarithmic Error),\n",
        "* média dos resíduos deviance.\n",
        "= aml.predict = ele traz a previsão de qual classe pertenceria, mas é preciso colocar um range.\n",
        "\n",
        "    \n",
        "    Quanto menor essas metricas melhor.\n",
        "Predições do Modelo: O H2O AutoML também faz predições no conjunto de teste usando o melhor modelo encontrado durante o processo de treinamento.\n",
        "\n",
        "As predições são exibidas como uma tabela com uma coluna contendo os valores previstos.\n",
        "\n",
        "2. Modelos\n",
        "\n",
        "Os modelos apresentados nos resultados são modelos gerados pelo H2O AutoML durante o processo de treinamento. O H2O AutoML é uma ferramenta que automatiza o processo de seleção e treinamento de vários modelos de machine learning, incluindo:"
      ],
      "metadata": {
        "id": "QjLxx86VpnLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Codigo"
      ],
      "metadata": {
        "id": "jaSSkJjNqMeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o"
      ],
      "metadata": {
        "id": "U_5r5-X6zuIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Inicializar H2O\n",
        "h2o.init()\n",
        "\n",
        "# Carregar dataset e converter para H2OFrame\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "df = h2o.H2OFrame(pd.concat([X, y], axis=1))\n",
        "\n",
        "# Dividir dataset em treino e teste\n",
        "train, test = df.split_frame(ratios=[0.8], seed=42)\n",
        "\n",
        "# Inicializar e treinar H2OAutoML\n",
        "aml = H2OAutoML(max_runtime_secs=120, seed=42)\n",
        "aml.train(y='target', training_frame=train)\n",
        "\n",
        "# Avaliar desempenho\n",
        "lb = aml.leaderboard\n",
        "print(lb)\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "preds = aml.predict(test)"
      ],
      "metadata": {
        "id": "ikh9j8Eaul7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Converter H2OFrame para pandas DataFrame\n",
        "preds_df = preds.as_data_frame()\n",
        "\n",
        "# Aplicar um limiar para converter probabilidades em previsões de classe\n",
        "previsoes_classes = np.round(preds_df)\n",
        "\n",
        "# Exibir as previsões de classe\n",
        "previsoes_classes\n"
      ],
      "metadata": {
        "id": "_V07M6m152aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para pegar o melhor modelo"
      ],
      "metadata": {
        "id": "cZznXzMF82Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model using the metric\n",
        "m = aml.leader\n",
        "# this is equivalent to\n",
        "m = aml.get_best_model()\n",
        "\n",
        "# Get the best model using a non-default metric\n",
        "m = aml.get_best_model(criterion=\"logloss\")\n",
        "\n",
        "# Get the best XGBoost model using default sort metric\n",
        "xgb = aml.get_best_model(algorithm=\"xgboost\")\n",
        "\n",
        "# Get the best XGBoost model, ranked by logloss\n",
        "xgb = aml.get_best_model(algorithm=\"xgboost\", criterion=\"logloss\")"
      ],
      "metadata": {
        "id": "Wi1tMQbl84kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para usar um modelo especifico do H2O"
      ],
      "metadata": {
        "id": "_K1xvhi74swd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo GBM específico pelo seu ID\n",
        "modelo_gbm = h2o.get_model(\"GBM_grid_1_AutoML_1_20240528_105427_model_1\")\n",
        "\n",
        "# Fazer previsões usando o modelo\n",
        "previsoes = modelo_gbm.predict(dados_teste)\n",
        "\n",
        "# Exibir as previsões\n",
        "print(previsoes)\n"
      ],
      "metadata": {
        "id": "YPrOh-YI4xEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLJAR"
      ],
      "metadata": {
        "id": "FfHq85-YDM5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLJAR é uma ferramenta de AutoML que automatiza a construção de modelos de machine learning, incluindo a pré-processamento de dados, engenharia de características, seleção de modelos, e ajuste de hiperparâmetros.\n",
        "\n",
        "Principais Funcionalidades:\n",
        "\n",
        "* Exploração de Modelos: Explora uma variedade de modelos de machine learning.\n",
        "* Relatórios Detalhados: Gera relatórios detalhados sobre o desempenho dos modelos.\n",
        "* Interface Web e API: Disponível tanto como uma plataforma web quanto como uma biblioteca Python."
      ],
      "metadata": {
        "id": "wQnoHXaJ-Ad_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mljar-supervised"
      ],
      "metadata": {
        "id": "vjgidiKR-OTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervised.automl import AutoML\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Dividir dataset em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inicializar e treinar AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar desempenho\n",
        "predictions = automl.predict_all(X_test)\n"
      ],
      "metadata": {
        "id": "a4VnJowE98XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "7FUKn1A6de2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost, ou eXtreme Gradient Boosting, é uma biblioteca popular de machine learning que implementa o algoritmo de gradient boosting. Ele é amplamente utilizado para problemas de classificação e regressão devido à sua eficácia e desempenho geralmente superior a outros métodos de aprendizado de máquina.\n",
        "\n",
        "O algoritmo de gradient boosting combina várias árvores de decisão fracas para criar um modelo forte. Ele funciona de forma iterativa, onde cada nova árvore é treinada para corrigir os erros cometidos pelos modelos anteriores. XGBoost aprimora esse processo com técnicas como regularização, função de perda personalizada e aprendizado de máquina distribuído."
      ],
      "metadata": {
        "id": "1gH3Ht7tdg-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir dataset em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Converter dados para formato DMatrix, que é específico para XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Definir os parâmetros do modelo\n",
        "param = {'max_depth': 3, 'eta': 0.3, 'objective': 'multi:softmax', 'num_class': 3}\n",
        "\n",
        "# Treinar o modelo\n",
        "num_round = 10\n",
        "model = xgb.train(param, dtrain, num_round)\n",
        "\n",
        "# Fazer previsões\n",
        "predictions = model.predict(dtest)\n",
        "\n",
        "# Avaliar o desempenho do modelo\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Acurácia:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71s1ieTWdqOi",
        "outputId": "53df7b7d-d3e9-4f99-9b78-50e15dc1a3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tecnica para ver o melhor parametro"
      ],
      "metadata": {
        "id": "JXlvWlsKd6RF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " O Grid Search é uma técnica que permite testar várias combinações de parâmetros especificados em uma grade pré-definida. Você pode usar a função GridSearchCV da biblioteca sklearn.model_selection para isso."
      ],
      "metadata": {
        "id": "P3_GQhG4eLdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir os parâmetros a serem testados\n",
        "param_grid = {'max_depth': [3, 6, 9], 'eta': [0.1, 0.3, 0.5], 'subsample': [0.8, 0.9, 1.0]}\n",
        "\n",
        "# Inicializar o modelo\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Realizar a busca em grade\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Exibir os melhores parâmetros\n",
        "print(\"Melhores parâmetros:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sldu02YeAJD",
        "outputId": "a0f49ff8-7de4-4860-c125-a22224c2f433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores parâmetros: {'eta': 0.1, 'max_depth': 3, 'subsample': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Search: Random Search é uma técnica semelhante ao Grid Search, mas em vez de testar todas as combinações possíveis, ele amostra aleatoriamente um subconjunto do espaço de parâmetros. Você pode usar a função RandomizedSearchCV da biblioteca sklearn.model_selection."
      ],
      "metadata": {
        "id": "5ArQd9JseYB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Definir os parâmetros a serem testados\n",
        "param_dist = {'max_depth': [3, 6, 9], 'eta': [0.1, 0.3, 0.5], 'subsample': [0.8, 0.9, 1.0]}\n",
        "\n",
        "# Inicializar o modelo\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Realizar a busca aleatória\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Exibir os melhores parâmetros\n",
        "print(\"Melhores parâmetros:\", random_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-FhybYOeY8L",
        "outputId": "4a68564d-6f48-41d5-ae12-d56aff56ce6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores parâmetros: {'subsample': 0.9, 'max_depth': 6, 'eta': 0.1}\n"
          ]
        }
      ]
    }
  ]
}